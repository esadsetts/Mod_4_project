{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Bag of Tweets\n",
    "\n",
    "####  Eryk Wdowiak and Eric Adsetts\n",
    "\n",
    "Module 4 project -- sentiment in Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# import re\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from  nltk import FreqDist\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>direction</th>\n",
       "      <th>emotion</th>\n",
       "      <th>target</th>\n",
       "      <th>company</th>\n",
       "      <th>product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>Apple</td>\n",
       "      <td>device</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>Apple</td>\n",
       "      <td>software</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>Apple</td>\n",
       "      <td>device</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>Apple</td>\n",
       "      <td>software</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>Google</td>\n",
       "      <td>company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@teachntech00 New iPad Apps For #SpeechTherapy...</td>\n",
       "      <td>nan</td>\n",
       "      <td>neutral</td>\n",
       "      <td>2</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>#SXSW is just starting, #CTIA is around the co...</td>\n",
       "      <td>Android</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>Google</td>\n",
       "      <td>device</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Beautifully smart and simple idea RT @madebyma...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>Apple</td>\n",
       "      <td>software</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Counting down the days to #sxsw plus strong Ca...</td>\n",
       "      <td>Apple</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>Apple</td>\n",
       "      <td>company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Excited to meet the @samsungmobileus at #sxsw ...</td>\n",
       "      <td>Android</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>Google</td>\n",
       "      <td>device</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                tweet           direction  \\\n",
       "0   .@wesley83 I have a 3G iPhone. After 3 hrs twe...              iPhone   \n",
       "1   @jessedee Know about @fludapp ? Awesome iPad/i...  iPad or iPhone App   \n",
       "2   @swonderlin Can not wait for #iPad 2 also. The...                iPad   \n",
       "3   @sxsw I hope this year's festival isn't as cra...  iPad or iPhone App   \n",
       "4   @sxtxstate great stuff on Fri #SXSW: Marissa M...              Google   \n",
       "5   @teachntech00 New iPad Apps For #SpeechTherapy...                 nan   \n",
       "7   #SXSW is just starting, #CTIA is around the co...             Android   \n",
       "8   Beautifully smart and simple idea RT @madebyma...  iPad or iPhone App   \n",
       "9   Counting down the days to #sxsw plus strong Ca...               Apple   \n",
       "10  Excited to meet the @samsungmobileus at #sxsw ...             Android   \n",
       "\n",
       "     emotion  target  company   product  \n",
       "0   negative       0    Apple    device  \n",
       "1   positive       1    Apple  software  \n",
       "2   positive       1    Apple    device  \n",
       "3   negative       0    Apple  software  \n",
       "4   positive       1   Google   company  \n",
       "5    neutral       2  unknown   unknown  \n",
       "7   positive       1   Google    device  \n",
       "8   positive       1    Apple  software  \n",
       "9   positive       1    Apple   company  \n",
       "10  positive       1   Google    device  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##  load data\n",
    "data = pd.read_csv('judge-1377884607_tweet_product_company_v2-clean.csv')\n",
    "data.columns = ['tweet','direction','emotion']\n",
    "# data.shape  # (9093, 3)\n",
    "\n",
    "##  remove rows without tweet\n",
    "data = data.dropna(subset=['tweet','emotion'],axis='index')\n",
    "# data.shape  # (9092, 3)\n",
    "\n",
    "##  clean emotions\n",
    "emo_dict = {'Negative emotion':'negative', \n",
    "            'Positive emotion':'positive',\n",
    "            'No emotion toward brand or product':'neutral', \n",
    "            \"I can't tell\":'neutral'}\n",
    "data['emotion'] = data['emotion'].replace(emo_dict)\n",
    "del emo_dict\n",
    "\n",
    "#Make target numeric\n",
    "target_dict = {'negative': 0,\n",
    "              'positive': 1,\n",
    "              'neutral': 2}\n",
    "data['target'] = data['emotion'].map(target_dict)\n",
    "##  define company and product\n",
    "##  first convert NaN to a string\n",
    "data['direction'] = data['direction'].map('{}'.format)\n",
    "\n",
    "##  define company\n",
    "comp_dict = {'iPhone':'Apple', \n",
    "             'iPad or iPhone App':'Apple', \n",
    "             'iPad':'Apple', \n",
    "             'Google':'Google', \n",
    "             'nan':'unknown', \n",
    "             'Android':'Google',\n",
    "             'Apple':'Apple',\n",
    "             'Android App':'Google', \n",
    "             'Other Google product or service':'Google',\n",
    "             'Other Apple product or service':'Apple'}\n",
    "data['company'] = data['direction'].replace(comp_dict)\n",
    "del comp_dict\n",
    "\n",
    "##  define product\n",
    "prod_dict = {'iPhone':'device', \n",
    "             'iPad or iPhone App':'software', \n",
    "             'iPad':'device', \n",
    "             'Google':'company', \n",
    "             'nan':'unknown', \n",
    "             'Android':'device',\n",
    "             'Apple':'company',\n",
    "             'Android App':'software', \n",
    "             'Other Google product or service':'other',\n",
    "             'Other Apple product or service':'other'}\n",
    "data['product'] = data['direction'].replace(prod_dict)\n",
    "del prod_dict\n",
    "\n",
    "##  let's take a look\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  prepare stop word list\n",
    "stopwords_list = stopwords.words('english')\n",
    "stopwords_list += list(string.punctuation)\n",
    "stopwords_list += ['0','1','2','3','4','5','6','7','8','9']\n",
    "\n",
    "##  process tweets\n",
    "def process_tweets(tweet):\n",
    "    tokens = word_tokenize(tweet)\n",
    "    wnl = WordNetLemmatizer()\n",
    "    no_stop_lemmas = [wnl.lemmatize(token.lower()) for token in tokens if token.lower() not in stopwords_list]\n",
    "    ot_string = ' '.join(no_stop_lemmas)\n",
    "    return ot_string\n",
    "\n",
    "##  process tweets\n",
    "data['tweet'] = list(map(process_tweets, list(data['tweet'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wesley83 3g iphone hr tweeting rise_austin dead need upgrade plugin station sxsw'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['tweet'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data[['tweet','company','product']], \n",
    "                                                    data['target'], \n",
    "                                                    test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>company</th>\n",
       "      <th>product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8256</th>\n",
       "      <td>next life 'm coming back ipad woman ca n't kee...</td>\n",
       "      <td>Apple</td>\n",
       "      <td>device</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6516</th>\n",
       "      <td>rt mention rt mention best thing 've heard wee...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7256</th>\n",
       "      <td>would love meet u rt mention 'll austin conven...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2116</th>\n",
       "      <td>iphone crashed front sxsw apple pop-up bestwor...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1545</th>\n",
       "      <td>mention mention mention platformer ci di venue...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5735</th>\n",
       "      <td>rt mention notatsxsw sxsw 's link free downloa...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5192</th>\n",
       "      <td>rt mention quot future local contextual discov...</td>\n",
       "      <td>Google</td>\n",
       "      <td>company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5391</th>\n",
       "      <td>rt mention android may gaining market share 'd...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>mention love mention mention sxsw quot apple c...</td>\n",
       "      <td>Apple</td>\n",
       "      <td>company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7271</th>\n",
       "      <td>anyone know status ipad 2 austin pop-up store ...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7273 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tweet  company  product\n",
       "8256  next life 'm coming back ipad woman ca n't kee...    Apple   device\n",
       "6516  rt mention rt mention best thing 've heard wee...  unknown  unknown\n",
       "7256  would love meet u rt mention 'll austin conven...  unknown  unknown\n",
       "2116  iphone crashed front sxsw apple pop-up bestwor...  unknown  unknown\n",
       "1545  mention mention mention platformer ci di venue...  unknown  unknown\n",
       "...                                                 ...      ...      ...\n",
       "5735  rt mention notatsxsw sxsw 's link free downloa...  unknown  unknown\n",
       "5192  rt mention quot future local contextual discov...   Google  company\n",
       "5391  rt mention android may gaining market share 'd...  unknown  unknown\n",
       "861   mention love mention mention sxsw quot apple c...    Apple  company\n",
       "7271  anyone know status ipad 2 austin pop-up store ...  unknown  unknown\n",
       "\n",
       "[7273 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  create TF-IDF matrix\n",
    "vectorizer = TfidfVectorizer(ngram_range = (1,3))\n",
    "tf_idf_data_train = vectorizer.fit_transform(X_train['tweet'])\n",
    "tf_idf_data_test = vectorizer.transform(X_test['tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes\n",
      "Training Accuracy: 0.9428\n",
      "Testing Accuracy:  0.6712\n",
      "Training f1: 0.9427\n",
      "Testing f1:  0.6531\n"
     ]
    }
   ],
   "source": [
    "##  naive bayes classifier\n",
    "nb_classifier = MultinomialNB(alpha = .1)\n",
    "\n",
    "nb_classifier.fit(tf_idf_data_train, y_train)\n",
    "nb_train_preds = nb_classifier.predict(tf_idf_data_train)\n",
    "nb_test_preds = nb_classifier.predict(tf_idf_data_test)\n",
    "\n",
    "nb_train_score = accuracy_score(y_train, nb_train_preds)\n",
    "nb_test_score = accuracy_score(y_test, nb_test_preds)\n",
    "nb_train_f1 = f1_score(y_train, nb_train_preds, average='weighted')\n",
    "nb_test_f1 = f1_score(y_test, nb_test_preds, average = 'weighted')\n",
    "\n",
    "print(\"Multinomial Naive Bayes\")\n",
    "print(\"Training Accuracy: {:.4}\".format(nb_train_score))\n",
    "print(\"Testing Accuracy:  {:.4}\".format(nb_test_score))\n",
    "print(\"Training f1: {:.4}\".format(nb_train_f1))\n",
    "print(\"Testing f1:  {:.4}\".format(nb_test_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6693246737285932\n",
      "{'alpha': 0.5}\n",
      "0.6178412200378456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    1.5s finished\n"
     ]
    }
   ],
   "source": [
    "#hyper parameter tuning\n",
    "nb_grid = GridSearchCV(nb_classifier, {'alpha': [.01,.1,.25,.5,1]}, n_jobs = -1, verbose = 1)\n",
    "nb_grid.fit(tf_idf_data_train, y_train)\n",
    "print(nb_grid.best_score_)\n",
    "print(nb_grid.best_params_)\n",
    "nb_grid_preds = nb_grid.predict(tf_idf_data_test)\n",
    "nb_grid_f1 = f1_score(y_test, nb_grid_preds, average = 'weighted')\n",
    "print(nb_grid_f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.5)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_optimal = MultinomialNB(alpha = .5)\n",
    "nb_optimal.fit(tf_idf_data_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forests\n",
      "Training Accuracy: 0.9953\n",
      "Testing Accuracy:  0.6597\n",
      "Training f1: 0.9953\n",
      "Testing f1:  0.613\n"
     ]
    }
   ],
   "source": [
    "##  random forests classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, class_weight = 'balanced', max_depth = None, n_jobs = -1)\n",
    "\n",
    "rf_classifier.fit(tf_idf_data_train, y_train)\n",
    "rf_train_preds = rf_classifier.predict(tf_idf_data_train)\n",
    "rf_test_preds = rf_classifier.predict(tf_idf_data_test)\n",
    "\n",
    "rf_train_score = accuracy_score(y_train, rf_train_preds)\n",
    "rf_test_score = accuracy_score(y_test, rf_test_preds)\n",
    "rf_train_f1 = f1_score(y_train, rf_train_preds, average='weighted')\n",
    "rf_test_f1 = f1_score(y_test, rf_test_preds, average = 'weighted')\n",
    "    \n",
    "print('Random Forests')\n",
    "print(\"Training Accuracy: {:.4}\".format(rf_train_score))\n",
    "print(\"Testing Accuracy:  {:.4}\".format(rf_test_score))\n",
    "print(\"Training f1: {:.4}\".format(rf_train_f1))\n",
    "print(\"Testing f1:  {:.4}\".format(rf_test_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  9.4min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed: 15.6min\n",
      "[Parallel(n_jobs=-1)]: Done 240 out of 240 | elapsed: 16.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6741376555727298\n",
      "{'max_depth': None, 'min_samples_split': 6, 'n_estimators': 500}\n",
      "0.643211554738738\n"
     ]
    }
   ],
   "source": [
    "#hyper parameter tuning\n",
    "rf_grid = GridSearchCV(rf_classifier, {'n_estimators' : [100,250,500],\n",
    "                                       'max_depth': [None, 1,3,5],\n",
    "                                       'min_samples_split': [2,6,10,20]},\n",
    "                       n_jobs = -1, verbose = 1)\n",
    "rf_grid.fit(tf_idf_data_train, y_train)\n",
    "print(rf_grid.best_score_)\n",
    "print(rf_grid.best_params_)\n",
    "rf_grid_preds = rf_grid.predict(tf_idf_data_test)\n",
    "rf_grid_f1 = f1_score(y_test, rf_grid_preds, average = 'weighted')\n",
    "print(rf_grid_f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_optimal = RandomForestClassifier(max_depth = None, min_samples_split = 6, n_estimators = 500, class_weight = 'balanced', n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Training Accuracy: 0.9229\n",
      "Testing Accuracy:  0.6526\n",
      "Training f1: 0.9234\n",
      "Testing f1:  0.6558\n"
     ]
    }
   ],
   "source": [
    "#Log Reg\n",
    "logreg = LogisticRegression(class_weight = 'balanced', n_jobs = -1)\n",
    "\n",
    "logreg.fit(tf_idf_data_train, y_train)\n",
    "lr_train_preds = logreg.predict(tf_idf_data_train)\n",
    "lr_test_preds = logreg.predict(tf_idf_data_test)\n",
    "\n",
    "lr_train_score = accuracy_score(y_train, lr_train_preds)\n",
    "lr_test_score = accuracy_score(y_test, lr_test_preds)\n",
    "lr_train_f1 = f1_score(y_train, lr_train_preds, average='weighted')\n",
    "lr_test_f1 = f1_score(y_test, lr_test_preds, average = 'weighted')\n",
    "    \n",
    "print('Logistic Regression')\n",
    "print(\"Training Accuracy: {:.4}\".format(lr_train_score))\n",
    "print(\"Testing Accuracy:  {:.4}\".format(lr_test_score))\n",
    "print(\"Training f1: {:.4}\".format(lr_train_f1))\n",
    "print(\"Testing f1:  {:.4}\".format(lr_test_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 13 candidates, totalling 65 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  50 tasks      | elapsed:   39.3s\n",
      "[Parallel(n_jobs=-1)]: Done  65 out of  65 | elapsed:   51.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6851351645183094\n",
      "{'C': 2}\n",
      "0.6674069043223244\n"
     ]
    }
   ],
   "source": [
    "#hyper parameter tuning\n",
    "lr_grid = GridSearchCV(logreg, {'C': [-1,-.5,-.1,.1,.5,1,1.5,2,2.5,10,20,25,50]},\n",
    "                       n_jobs = -1, verbose = 1)\n",
    "lr_grid.fit(tf_idf_data_train, y_train)\n",
    "print(lr_grid.best_score_)\n",
    "print(lr_grid.best_params_)\n",
    "lr_grid_preds = lr_grid.predict(tf_idf_data_test)\n",
    "lr_grid_f1 = f1_score(y_test, lr_grid_preds, average = 'weighted')\n",
    "print(lr_grid_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_optimal = LogisticRegression(class_weight = 'balanced', n_jobs = -1, C = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree\n",
      "Training Accuracy: 0.9953\n",
      "Testing Accuracy:  0.5954\n",
      "Training f1: 0.9953\n",
      "Testing f1:  0.5939\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree\n",
    "tree = DecisionTreeClassifier(class_weight = 'balanced')\n",
    "\n",
    "tree.fit(tf_idf_data_train, y_train)\n",
    "dt_train_preds = tree.predict(tf_idf_data_train)\n",
    "dt_test_preds = tree.predict(tf_idf_data_test)\n",
    "\n",
    "dt_train_score = accuracy_score(y_train, dt_train_preds)\n",
    "dt_test_score = accuracy_score(y_test, dt_test_preds)\n",
    "dt_train_f1 = f1_score(y_train, dt_train_preds, average='weighted')\n",
    "dt_test_f1 = f1_score(y_test, dt_test_preds, average = 'weighted')\n",
    "    \n",
    "print('Decision Tree')\n",
    "print(\"Training Accuracy: {:.4}\".format(dt_train_score))\n",
    "print(\"Testing Accuracy:  {:.4}\".format(dt_test_score))\n",
    "print(\"Training f1: {:.4}\".format(dt_train_f1))\n",
    "print(\"Testing f1:  {:.4}\".format(dt_test_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 175 candidates, totalling 875 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   25.5s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 875 out of 875 | elapsed:  3.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5784370169741488\n",
      "{'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 4}\n",
      "0.5983203933920344\n"
     ]
    }
   ],
   "source": [
    "#hyper parameter tuning\n",
    "dt_grid = GridSearchCV(tree, {'max_depth': [None, 50,25,10,5], 'min_samples_split': [2,4,8,10,12,14,16],\n",
    "                             'min_samples_leaf': [1,5,10,15,20]},\n",
    "                       n_jobs = -1, verbose = 1)\n",
    "dt_grid.fit(tf_idf_data_train, y_train)\n",
    "print(dt_grid.best_score_)\n",
    "print(dt_grid.best_params_)\n",
    "dt_grid_preds = dt_grid.predict(tf_idf_data_test)\n",
    "dt_grid_f1 = f1_score(y_test, dt_grid_preds, average = 'weighted')\n",
    "print(dt_grid_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_optimal = DecisionTreeClassifier(class_weight = 'balanced', max_depth = None, min_samples_leaf = 1, min_samples_split = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K Nearest Neighbors\n",
      "Training Accuracy: 0.7447\n",
      "Testing Accuracy:  0.6311\n",
      "Training f1: 0.7307\n",
      "Testing f1:  0.6079\n"
     ]
    }
   ],
   "source": [
    "#KNN\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "knn.fit(tf_idf_data_train, y_train)\n",
    "knn_train_preds = knn.predict(tf_idf_data_train)\n",
    "knn_test_preds = knn.predict(tf_idf_data_test)\n",
    "\n",
    "knn_train_score = accuracy_score(y_train, knn_train_preds)\n",
    "knn_test_score = accuracy_score(y_test, knn_test_preds)\n",
    "knn_train_f1 = f1_score(y_train, knn_train_preds, average='weighted')\n",
    "knn_test_f1 = f1_score(y_test, knn_test_preds, average = 'weighted')\n",
    "    \n",
    "print('K Nearest Neighbors')\n",
    "print(\"Training Accuracy: {:.4}\".format(knn_train_score))\n",
    "print(\"Testing Accuracy:  {:.4}\".format(knn_test_score))\n",
    "print(\"Training f1: {:.4}\".format(knn_train_f1))\n",
    "print(\"Testing f1:  {:.4}\".format(knn_test_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    6.2s\n",
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed:   20.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6445766389200074\n",
      "{'n_neighbors': 1, 'p': 1}\n",
      "0.6093983363997821\n"
     ]
    }
   ],
   "source": [
    "#hyper parameter tuning\n",
    "knn_grid = GridSearchCV(knn, {'n_neighbors': [1,3,5,7,9,11,13,15], 'p': [1,2,3]},\n",
    "                       n_jobs = -1, verbose = 1)\n",
    "knn_grid.fit(tf_idf_data_train, y_train)\n",
    "print(knn_grid.best_score_)\n",
    "print(knn_grid.best_params_)\n",
    "knn_grid_preds = knn_grid.predict(tf_idf_data_test)\n",
    "knn_grid_f1 = f1_score(y_test, knn_grid_preds, average = 'weighted')\n",
    "print(knn_grid_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_optimal = KNeighborsClassifier(n_neighbors = 1, p = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machines\n",
      "Training Accuracy: 0.9432\n",
      "Testing Accuracy:  0.6658\n",
      "Training f1: 0.9436\n",
      "Testing f1:  0.6617\n"
     ]
    }
   ],
   "source": [
    "#SVM\n",
    "svm = SVC(class_weight = 'balanced')\n",
    "\n",
    "svm.fit(tf_idf_data_train, y_train)\n",
    "svm_train_preds = svm.predict(tf_idf_data_train)\n",
    "svm_test_preds = svm.predict(tf_idf_data_test)\n",
    "\n",
    "svm_train_score = accuracy_score(y_train, svm_train_preds)\n",
    "svm_test_score = accuracy_score(y_test, svm_test_preds)\n",
    "svm_train_f1 = f1_score(y_train, svm_train_preds, average='weighted')\n",
    "svm_test_f1 = f1_score(y_test, svm_test_preds, average = 'weighted')\n",
    "    \n",
    "print('Support Vector Machines')\n",
    "print(\"Training Accuracy: {:.4}\".format(svm_train_score))\n",
    "print(\"Testing Accuracy:  {:.4}\".format(svm_test_score))\n",
    "print(\"Training f1: {:.4}\".format(svm_train_f1))\n",
    "print(\"Testing f1:  {:.4}\".format(svm_test_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 28 candidates, totalling 140 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "/Users/ericadsetts/opt/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 140 out of 140 | elapsed:  5.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.684860061354623\n",
      "{'C': 10, 'kernel': 'linear'}\n",
      "0.6672589469062217\n"
     ]
    }
   ],
   "source": [
    "#hyper parameter tuning\n",
    "svm_grid = GridSearchCV(svm, {'C': [.5,1,5,10,15,25,50],\n",
    "                             'kernel': ['linear', 'poly', 'rbf', 'sigmoid']},\n",
    "                       n_jobs = -1, verbose = 1)\n",
    "svm_grid.fit(tf_idf_data_train, y_train)\n",
    "print(svm_grid.best_score_)\n",
    "print(svm_grid.best_params_)\n",
    "svm_grid_preds = svm_grid.predict(tf_idf_data_test)\n",
    "svm_grid_f1 = f1_score(y_test, svm_grid_preds, average = 'weighted')\n",
    "print(svm_grid_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_optimal = SVC(class_weight = 'balanced', C = 10, kernel = 'linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:57:58] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { num_classes } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Support Vector Machines\n",
      "Training Accuracy: 0.8549\n",
      "Testing Accuracy:  0.6723\n",
      "Training f1: 0.8464\n",
      "Testing f1:  0.6357\n"
     ]
    }
   ],
   "source": [
    "xgb_clf = xgb.XGBClassifier(objective = 'multi:softmax', num_classes = 3, n_jobs = -1,\n",
    "                            verbosity = 1)\n",
    "\n",
    "xgb_clf.fit(tf_idf_data_train, y_train)\n",
    "xgb_train_preds = xgb_clf.predict(tf_idf_data_train)\n",
    "xgb_test_preds = xgb_clf.predict(tf_idf_data_test)\n",
    "\n",
    "xgb_train_score = accuracy_score(y_train, xgb_train_preds)\n",
    "xgb_test_score = accuracy_score(y_test, xgb_test_preds)\n",
    "xgb_train_f1 = f1_score(y_train, xgb_train_preds, average='weighted')\n",
    "xgb_test_f1 = f1_score(y_test, xgb_test_preds, average = 'weighted')\n",
    "    \n",
    "print('Support Vector Machines')\n",
    "print(\"Training Accuracy: {:.4}\".format(xgb_train_score))\n",
    "print(\"Testing Accuracy:  {:.4}\".format(xgb_test_score))\n",
    "print(\"Training f1: {:.4}\".format(xgb_train_f1))\n",
    "print(\"Testing f1:  {:.4}\".format(xgb_test_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 405 candidates, totalling 2025 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  9.6min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed: 24.4min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed: 48.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed: 84.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1784 tasks      | elapsed: 137.0min\n",
      "[Parallel(n_jobs=-1)]: Done 2025 out of 2025 | elapsed: 164.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:43:11] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { num_classes } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "0.680185103778178\n",
      "{'colsample_bytree': 1, 'eta': 0.01, 'max_depth': 6, 'min_child_weight': 0.1, 'subsample': 1}\n",
      "0.6508281569125254\n"
     ]
    }
   ],
   "source": [
    "#hyper parameter tuning\n",
    "xgb_grid = GridSearchCV(xgb_clf, {'eta': [.01,.05,.1,.15,.2], 'min_child_weight': [.1, 1, 10], 'max_depth': [3, 6, 10],\n",
    "                                 'subsample': [.5, .75, 1], 'colsample_bytree': [.5,.75,1]},\n",
    "                       n_jobs = -1, verbose = 1)\n",
    "xgb_grid.fit(tf_idf_data_train, y_train)\n",
    "print(xgb_grid.best_score_)\n",
    "print(xgb_grid.best_params_)\n",
    "xgb_grid_preds = xgb_grid.predict(tf_idf_data_test)\n",
    "xgb_grid_f1 = f1_score(y_test, xgb_grid_preds, average = 'weighted')\n",
    "print(xgb_grid_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_optimal = xgb.XGBClassifier(objective = 'multi:softmax', num_classes = 3, n_jobs = -1, colsample_bytree = .5,\n",
    "                                eta = 0.01, max_depth = 6, min_child_weight = 0.1, subsample = 1,\n",
    "                            verbosity = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier\n",
      "Training Accuracy: 0.9812\n",
      "Testing Accuracy:  0.6811\n",
      "Training f1: 0.9811\n",
      "Testing f1:  0.6539\n"
     ]
    }
   ],
   "source": [
    "voting_clf = VotingClassifier(estimators = [('nb', nb_optimal), ('rf', rf_optimal), ('lr', lr_optimal),('tree', dt_optimal), \n",
    "                                            ('knn', knn_optimal), ('svm', svm_optimal), ('xgb', xgb_optimal)],\n",
    "                              n_jobs = -1)\n",
    "\n",
    "voting_clf.fit(tf_idf_data_train, y_train)\n",
    "voting_train_preds = voting_clf.predict(tf_idf_data_train)\n",
    "voting_test_preds = voting_clf.predict(tf_idf_data_test)\n",
    "\n",
    "voting_train_score = accuracy_score(y_train, voting_train_preds)\n",
    "voting_test_score = accuracy_score(y_test, voting_test_preds)\n",
    "voting_train_f1 = f1_score(y_train, voting_train_preds, average='weighted')\n",
    "voting_test_f1 = f1_score(y_test, voting_test_preds, average = 'weighted')\n",
    "    \n",
    "print('Voting Classifier')\n",
    "print(\"Training Accuracy: {:.4}\".format(voting_train_score))\n",
    "print(\"Testing Accuracy:  {:.4}\".format(voting_test_score))\n",
    "print(\"Training f1: {:.4}\".format(voting_train_f1))\n",
    "print(\"Testing f1:  {:.4}\".format(voting_test_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
